---
layout: single
title:  "Linear Programming笔记"
date:   2024-03-22 12:19:36 +0800
categories: Linear-Programming
---
这一篇是Linear Programming的笔记。主要总结了两本书的部分内容：
- Linear and nonlinear programming
- Introduction to Linear Optimization


 

## 1. 一些基本概念

考虑如下基本的LP问题：
$$
\begin{align}
\min_{\mathbf{x}} \ & \mathbf{c}^{\top} \mathbf{x} \\  
\text{s.t.} \ & \mathbf{A} \mathbf{x} = \mathbf{b} \\ 
\ & \mathbf{x} \geq 0. 
\end{align}
$$
不失一般性，我们可以假设$\mathbf{b}\in \mathbb{R}^m \geq 0$. 其中$\mathbf{x} \in \mathbb{R}^n$。其他参数的维度对应。其他不符合这个形式LP都可以通过加Slack variables, surplus variables来进行转换。如果是free variables，可以通过$x= x_1 - x_2$或者变量替换来转换。

通过消除$Ax = b$中的多余约束，我们要么发现它不可行，要么可以得到$A$的所有row是线性独立的。所以，不失一般性，我们可以假设
> Full Rank Assumption: The m × n matrix A has m < n, and the m rows of A are linearly
independent. (如果m=n，就只有一个解了，很trival了)

下面介绍一些定义：

- Basic Solution
```
Given the set of m simultaneous linear equations in n unknowns (Ax=b), let B be any nonsingular m×m submatrix made up of columns of A. Then, if all n − m components of x not associated with columns of B are set equal to zero, the solution to the resulting set of equations is said to be a basic solution to (Ax=b) with respect to basis B. The components of x associated with the columns of B, denoted by subvector $x_B$ according to the same column index order in B, are called basic variables.
```

- Degenerate Basic Solution: If one or more of the basic variables in a basic solution has value zero, that
solution is said to be a degenerate basic solution.

- Basic Feasible Solution: 满足$\mathbf{x} \geq 0$ 的Basic Solution.

- Degenerate Basic Feasible Solution

基于这些定义，我们可以给出下面的Fundamental Theorem of Linear Programming:  
1. If there is a feasible solution for LP, there is a basic feasible solution
2. If there is an optimal feasible solution for LP, there is an optimal basic feasible solution

Proof of 1, 假设$\mathbf{x}$是一个可行解 (同时只有前p个conponents非0)，那么
$$
x_1 \mathbf{a}_1 + ... + x_p \mathbf{a}_p = \mathbf{b}. 
$$
只会出现两种情况
- 如果$\mathbf{a}_1, ..., \mathbf{a}_p$线性独立，根据full rank assumption，$p\leq m$，那么我们很简单就找了一个(degenerated) basic feasible solution.
- 如果$\mathbf{a}_1, ..., \mathbf{a}_p$线性相关，那么肯定存在$y_1, ..., y_p$其中至少一个大于0，使得$y_1 \mathbf{a}_1 + ... + y_p \mathbf{a}_p = 0$. 同时，我们有
$$
(x_1 - \epsilon y_1) \mathbf{a}_1 + ... + (x_p - \epsilon y_p) \mathbf{a}_p = \mathbf{b}, \ 
\forall \epsilon
$$
这说明$\mathbf{x} - \epsilon \mathbf{y}$满足$Ax=b$。因为至少一个$y_i$大于0，那么$\mathbf{x} - \epsilon \mathbf{y}$中肯定有一个component会减小当$\epsilon$增加。 让$\epsilon = \min\{ x_i/y_i : y_i >0 \}$，我们一定可以找到一个新的可行解（其中最多p-1个components大于0）。重复这个过程，就可以让所有列都线性对立，变成第一种情况了。

Proof of 2, 假设$\mathbf{x}$是一个optimal solution，也只会有两种情况
- 线性独立，如上
- 线性不独立，只需要说明$\mathbf{x} - \epsilon \mathbf{y}$是最优的就行。当$\epsilon$的绝对值充分小的时候，$\mathbf{x} - \epsilon \mathbf{y}$是可行的，但是$\mathbf{c}^{\top} \mathbf{x} - \epsilon \mathbf{c}^{\top} \mathbf{y}$可能比最优解还小(如果$\mathbf{c}^{\top} \mathbf{y}$不为0).所以$\mathbf{c}^{\top} \mathbf{y}$只能为0，那么$\mathbf{x} - \epsilon \mathbf{y}$还是最优的。 



上面这部分内容都是给出了LP的一些代数上的解释，我们可以从$n$列中选出m个做basic，然后一个一个比较大小，解LP。下面呢，给出一个convex geometry的解释。

- Extreme point: A point x in a convex set C is said to be an extreme point of C if there are no two distinct points x1 and x2 in C such that x = αx1 + (1 − α)x2 for some α, 0 < α < 1.
- Equivalence of Extreme Points and Basic Feasible Solutions: Let A be an m × n matrix
of rank m and b an m-vector. Let K be the convex polytope consisting of all n-vectors x satisfying $Ax=b, x\geq 0$. A vector x is an extreme point of K if and only if x is a basic feasible solution. 
- Corollary 1: If the convex set K corresponding to $Ax=b, x\geq 0$ is nonempty, it has at least one extreme point.
- Corollary 2: If there is a finite optimal solution to a linear programming problem, there is a finite optimal solution which is an extreme point of the constraint set.
- Corollary 3: The constraint set K corresponding to $Ax=b, x\geq 0$ possesses at most a finite number of extreme points and each of them is finite.
- Corollary 4: If the convex polytope K corresponding to $Ax=b, x\geq 0$ is bounded, then K is a convex polyhedron, that is, K consists of points that are convex combinations of a finite number of points.



在这一小节的最后，介绍一下Farkas' Lemma, 它是说一个linear system有解，对应另一个linear system无解。

$Ax=b,x\geq 0$ 有可行解，iff， $\mathbf{y}^{\top} \mathbf{A} \leq 0, \mathbf{y}^{\top} \mathbf{b} = 1 \ (\text{or } >0)$没有可行解。

证明之前，先给出下面的lemma：
Let C be the cone generated by the columns of matrix A, that is, $C = {Ax ∈ E^m : x \geq 0}$.
Then C is a closed and convex set.

Proof of Farkas' Lemma: 
- 如果前者有一个可行解$\overline{\mathbf{x}}$，那么我们有一个矛盾存在
$$
0 < \mathbf{y}^{\top} \mathbf{b} = \mathbf{y}^{\top} (\mathbf{A} \overline{\mathbf{x}}) = (\mathbf{y}^{\top} \mathbf{A} )\overline{\mathbf{x}} \leq 0 
$$
- 如果前者没有可行解，我们要证明后者有可行解。$\mathbf{b} \notin C = \{Ax : x \geq 0\}$, by lemma 1 and separating hyperplane theorem, 总存在一个$\mathbf{y}$
$$
\mathbf{y}^{\top} \mathbf{b} > \sup_{c \in C} \mathbf{y}^{\top} \mathbf{c} = \sup_{x\geq 0} (\mathbf{y}^{\top} \mathbf{A}) \mathbf{x} \geq 0 
$$
同时，很显然，$\mathbf{y}^{\top} \mathbf{A} \leq 0$，如果不小于， $\sup_{x\geq 0} (\mathbf{y}^{\top} \mathbf{A}) \mathbf{x}$ 会等于正无穷。（=1 是因为我们总可以缩放y使得等于1)


The geometric interpretation of the lemma is quite clear: if b is not in the closed
and convex cone generated by the columns of matrix A, then there must be a
hyperplane separating b and the cone, and feasible solution y to the alternative
system is the slope-vector of the hyperplane.


## 2. Duality and Complementarity


![x](../assets/images/LPdual.png)

对偶变量又可以叫做price。

考虑如下问题以及对偶
$$
\begin{align}
\min_{\mathbf{x}} \ & \mathbf{c}^{\top} \mathbf{x} \\  
\text{s.t.} \ & \mathbf{A} \mathbf{x} = \mathbf{b}  \\ 
\ & \mathbf{x} \geq 0. 
\end{align}
$$

$$
\begin{align}
\min_{\mathbf{y}} \ & \mathbf{y}^{\top} \mathbf{b} \\  
\text{s.t.} \ & \mathbf{y}^{\top} \mathbf{A} \leq \mathbf{c}^{\top}
\end{align}
$$
这里我们不做full rank assumption。

Lemma 1 (Weak Duality Lemma): If x and y are feasible for Pimary and Dual,respectively,
then $\mathbf{c}^{\top} \mathbf{x} \geq  \mathbf{y}^{\top} \mathbf{b}$.

Corollary: If $x_0$ and $y_0$ are feasible for Pimary and Dual, respectively, and if $\mathbf{c}^{\top} \mathbf{x}_0 =  \mathbf{y}_0^{\top} \mathbf{b}$, then x0 and y0 are optimal for their respective problems.

Duality Theorem of Linear Programming: If either of the problems Pimary and Dual has a finite optimal solution, so does the other, and the corresponding values of the objective functions are equal. If either problem has an unbounded objective, the other problem has no feasible solution.

下面给出一些Geometric and Economic Interpretations

定义一个Dual Basic Solution: $\mathbf{y}^{\top} = \mathbf{c}^{\top}_B \mathbf{B}^{-1}$，这个y又可以叫做 dual multipliers, simplex multipliers, shadow prices

Theorem: Let the linear program Primary have an optimal basic feasible solution corresponding to the basis B. Then the vector y satisfying $\mathbf{y}^{\top} = \mathbf{c}^{\top}_B \mathbf{B}^{-1}$ is an optimal solution to the dual program if it is dual feasible. The optimal values of both problems are equal.

给定任何basis $\mathbf{B}$，我们知道每一个$\mathbf{a}_j$有一个unit cost $c_j$与之关联。现在呢，我们想把这个unit cost转换成与每一个$\mathbf{e}_i$相关联，那么就需要接等式$c_i = \mathbf{a}_j^{\top} \mathbf{y}$, i.e., $\mathbf{y}^{\top} \mathbf{B} = \mathbf{c}^{\top}$, 只需要$\mathbf{y}^{\top} = \mathbf{c}^{\top}_B \mathbf{B}^{-1}$。所以，y可以解释成$e_i$的unit cost。

这样做以后，任何一个vector，我们都可以给出它的synthetic cost。The difference between the true cost of this vector and the synthetic cost is the relative cost. The process of calculating the synthetic cost of a vector, with respect to a given basis, by using the simplex multipliers is sometimes referred to as pricing out the vector.

Optimality of the primal corresponds to the situation where every vector a1, a2,
. . . , an is cheaper when constructed from the basis than when purchased directly
at its own price, i.e., $\mathbf{y}^{\top} \mathbf{A} \leq \mathbf{c}^{\top}$. 
> 最后这段话优点难理解？

下面介绍下sensitivity and complementary slackness 

Theorem: The minimal value function z(b) of linear program is a convex function, and the optimal dual solution $y^*$ is a sub-gradient vector of the function at b, written as
∇z(b) = $y^*$.


下面是complementary slackness 

Theorem (Complementary slackness—asymmetric form)： Let x and y be feasible
solutions for the primal and dual programs, respectively. A necessary
and sufficient condition that they both be optimal solutions is that for all j
1. $x_j > 0 \Rightarrow y^T a_j = c_j$
2. $x_j = 0 \Leftarrow y^T a_j < c_j$

Theorem (Strict complementary slackness—asymmetric form): Let both the primal and
dual problems of be feasible. Then there is an optimal solution pair x and y such that
for all j
1. $x_j > 0 \iff y^T a_j = c_j$
2. $x_j = 0 \iff y^T a_j < c_j$


Corollary 1 (Complementary slackness—symmetric form): Let x and y be feasible
solutions for the primal and dual programs, respectively, in the pair of symmetric form. A necessary and sufficient condition that they both be optimal solutions is that for all i and j
1. xj > 0 ⇒ yT aj = cj
2. xj = 0 ⇐ yT aj < cj
3. yi > 0 ⇒ aix = bi
4. yi = 0 ⇐ aix > bi 


对偶领域很经典的问题，max flow - min cut

## 3. The Simplex method 

单纯行法的基本思想是 从一个basic feasible solution（extreme point）移动到一个adjacent one。
> Definition Two basic feasible solutions are said to be adjacent if and only if they differ by one basic variable.

Nondegeneracy Assumption: Every basic feasible solution of the standard form is a nondegenerate basic feasible solution. 

下面先介绍如果决定那个vector离开basic：

假设$\mathbf{a}_{e}$为进basic向量，那么$\mathbf{b} = \mathbf{B}\mathbf{x}_B + \mathbf{a}_e x_e$. 我们定义$\overline{\mathbf{a}}_0 = \mathbf{B}^{-1} \mathbf{b}$ and $\overline{\mathbf{a}}_e = \mathbf{B}^{-1} \mathbf{a}_e$，那么
$$
\mathbf{x}_B = \overline{\mathbf{a}}_0 - \overline{\mathbf{a}}_e x_e
$$

这样，我们知道选择最小的
$$
x_e = \epsilon = \min_{i} \{  \overline{a}_{i0} / \overline{a}_{ie} : \overline{a}_{ie} > 0  \}
$$
出basic向量就选择对应的i，记为$o$。如果有多个i，那么new solution是degenerate, 如果没有$\overline{a}_{ie} > 0$，那么意味着feasible region是unbounded。

接下来就可以介绍primary simplex method了，
$$
z = z_0 + (\mathbf{c}_D^{\top} - \mathbf{y}^{\top} \mathbf{D}) \mathbf{x}_D 
$$
其中$z_0 = c_B^T B^{-1} b$。 $\mathbf{r}_D^{\top} = \mathbf{c}_D^{\top} - \mathbf{y}^{\top} \mathbf{D}$为relative cost or reduced cost or reduced gradient vector.

Theorem (Improvement of Basic Feasible Solution): Given a **nondegenerate basic feasible solution** with corresponding objective value z_0, suppose that for some j there holds r_j < 0. Then there is a feasible solution with objective value z < z_0. If the column a_j can be substituted for some vector in the original basis to yield a new basic feasible solution, this new solution will have z < z0. If a_j cannot be substituted to yield a basic feasible solution, then the solution set K is unbounded and the objective function can be made arbitrarily small (toward minus infinity).

Optimality Condition Theorem If for some basic feasible solution $r_j \geq 0$ for all j, then that solution is optimal.

![x](../assets/images/SimplexMethod.jpg)

Another popular technique to solve linear programs, when n >> m in the standard form, is called Column Generation.


> In practice, however, Degeneracy cycle aviod procedures are found to be unnecessary. When degenerate solutions are encountered, the simplex procedure generally does not enter a cycle. However, anticycling procedures are simple, and many codes incorporate such a procedure for the sake of safety. for example, Bland’s rule

下一个问题是how to find an Initial Basic Feasible Solution
> consider the artificial minimization problem (commonly called the Phase One linear program).
$$
\begin{align}
\min \ & \sum u_j \\
\text{s.t} \ & Ax + u = b \\
\ & x \geq 0, u \geq 0
\end{align}
$$
最优的u等于0的话，原问题有解，同时找到了一个初事解。不等于0，无解。


下面介绍The Dual Simplex Method.

通常会遇到的情况是，a basic不可行，但是对应的multiplier是可行的。$\mathbf{y}^T = c_B^T B^{-1}, r_D^T = c_D^T - y^T D \geq 0$.  If the dual basic feasible solution is nondegenerate, the inequality holds strictly component-wise. Then we can apply the dual simplex method moving from the current solution to a new dual basic feasible solution with a better objective value.

考虑如下对偶问题
$$
\begin{align}
\max \ & \mathbf{y}^{\top} \mathbf{b} \\
\text{s.t} \ & \mathbf{y}^{\top} \mathbf{B} \leq \mathbf{c}_B^T \\
\ & \mathbf{y}^{\top} \mathbf{D} \leq \mathbf{c}_D^T
\end{align}
$$

定义一个 affine transformation:$\mathbf{y}^{\prime \top} = \mathbf{y}^{\top} \mathbf{B} - \mathbf{c}_B^{\top}$ or $\mathbf{y}^{\top} = (\mathbf{y}^{\prime} + \mathbf{c}_B)^{\top} \mathbf{B}^{-1}$。对偶问题变成了，
$$
\begin{align}
\max \ & \mathbf{y}^{\prime \top} \mathbf{B}^{-1} \mathbf{b} + \mathbf{c}_B^{\top} \mathbf{B}^{-1} \mathbf{b} \\
\text{s.t} \ & \mathbf{y}^{\prime} \leq 0  \\
\ & \mathbf{y}^{\prime \top} \mathbf{B}^{-1} \mathbf{D}  \leq \mathbf{c}_D^T -  \mathbf{c}_B^{\top} \mathbf{B}^{-1} \mathbf{D}
\end{align}
$$
等价于
$$
\begin{align}
\max \ & \mathbf{y}^{\prime \top} \overline{\mathbf{a}}_0 + z_0 \\
\text{s.t} \ & \mathbf{y}^{\prime} \leq 0  \\
\ & \mathbf{y}^{\prime \top} \mathbf{B}^{-1} \mathbf{D}  \leq \mathbf{r}_D^{\top}
\end{align}
$$
很显然，$ \mathbf{y}^{\prime} = 0$ 是可行的，同时如果$\overline{\mathbf{a}}_0 \geq 0$, 它是最优的。

如果有$\overline{a}_{o0} < 0$, 那么我们可以减小$\mathbf{y}^{\prime}_o$ 到 $-\epsilon$。（19）很显然是满足。对于（20），在nondegeneracy 假设下(r_D > 0)， 它变成了
$$
-\epsilon \mathbf{e}_0^{\top} \mathbf{B}^{-1} \mathbf{D} \leq \mathbf{r}_D^{\top}, or, -\epsilon \overline{\mathbf{a}}^o \leq \mathbf{r}_D^{\top}
$$

if all entries in ¯ao are nonnegative, then we can choose ε infinitely
large so that the dual objective is unbounded. If some of them are negative, we
can increase ε until one of the inequality constraints become equal in (4.17). The
one, say the eth that becomes equality, indicates that the current nonbasic column
ae replaces ao in the new basis B.

here the outgoing column is selected first and the incoming one is chosen later.

![x](../assets/images/dualSimplexMethod.jpg)


接下来是The Primal–Dual Algorithm.

> it can be regarded as striving to achieve the complementary slackness conditions for optimality.

这几种算法的关系：Originally, the primal–dual method was developed for solving a special
kind of linear program arising in network flow problems, and it continues to be the
most efficient procedure for these problems. (For general linear programs the dual
simplex method is most frequently used).

考虑如下问题以及对偶
$$
\begin{align}
\min_{\mathbf{x}} \ & \mathbf{c}^{\top} \mathbf{x} \\  
\text{s.t.} \ & \mathbf{A} \mathbf{x} = \mathbf{b}  \\ 
\ & \mathbf{x} \geq 0. 
\end{align}
$$

$$
\begin{align}
\max_{\mathbf{y}} \ & \mathbf{y}^{\top} \mathbf{b} \\  
\text{s.t.} \ & \mathbf{y}^{\top} \mathbf{A} \leq \mathbf{c}^{\top}
\end{align}
$$
给定一个对偶可行解(dual feasible solution) $\mathbf{y}$，定义一个subset $P$ 为所有满足$\mathbf{y}^{\top} \mathbf{a}_j = c_j$的j，然后我们考虑下面这个 associated restricted primary problem:
$$
\begin{align}
\min \ & \mathbf{1}^{\top} \mathbf{u} \\  
\text{s.t.} \ & \mathbf{A} \mathbf{x} + \mathbf{u} = \mathbf{b}  \\ 
\ & \mathbf{x} \geq 0, \ x_j = 0 \forall j \notin P , \\ 
\ & \mathbf{u} \geq 0
\end{align}
$$
associated restricted dual problem: 
$$
\begin{align}
\max \ & \mathbf{y}^{\prime \top} \mathbf{b} \\  
\text{s.t.} \ & \mathbf{y}^{\prime \top} \mathbf{a}_j \leq 0, j \in P, \\
\ & \mathbf{y}^{\prime} \leq 1 
\end{align}
$$

Primal-Dual Optimality Theorem: Suppose that y is feasible for the original dual and
that x and u = 0 is feasible (and of course optimal) for the associated restricted primal.
Then x and y are optimal for the original primal and dual programs, respectively.

![x](../assets/images/primarydualSimplexMethod.jpg)


## 3. 大规模LP算法

1. 列生成
2. 切平面 （对原问题列生成 等价于 对对偶问题切平面）

Dantzig–Wolfe decomposition 是一种formulation思想，核心是列生成。
Benders decomposition也是一种formulation思想  核心是切平面


![x](../assets/images/DWforLP1.jpg)
![x](../assets/images/DWforLP2.jpg)


## 4. Interior-Point method 

下面先介绍一下complexity theory, 我们需要先定义下面三个概念：
1. input size
2. basic operations
3. cost for each basic operation

具体的可以看后面IP部分笔记。

接下来是ellipsoid method 

定义一个Polyhedral set $\Omega = \{ \mathbf{y} \in E^m : \mathbf{y}^{\top} \mathbf{a}_j \leq c_j, j = 1,...,n \}$

有如下两个假设
1. There is a vector $\mathbf{y}_0 \in E^m$ and a scalar R > 0 such that the closed ball S(y0, R) $=\{\mathbf{y} \in E^m : | \mathbf{y} - \mathbf{y}_0| \leq R \}$ with center y0 and radius R contains $\Omega$. 
2. If $\Omega$ is nonempty, there is a scalar r > 0 such that $\Omega$ contains a ball of the form S(y, r) with center at some y ∈ $\Omega$ and radius r. (This assumption
implies that if $\Omega$ is nonempty, then it has a nonempty interior and its volume
is at least vol(S(0, r)).)

Def: An ellipsoid in $E^m$ is a set of the form:
$$
E(z,Q) = \{ y \in E^m : (y-z)^{\top} \mathbf{Q} (y-z) \leq 1 \}
$$
其中z是center，Q是PSD的。axes对应Q的eigenvectors，长度为 $\lambda^{-1/2}$。ellipsoid的体积为：
$$
vol(E) = vol(S(0,1)) \prod \lambda_i^{-1/2 }
$$

接下来是算法部分
1. $B_0 = R^2 I$, $Q_0 = B_0^{-1}$，这样$E_0$就包含了$\Omega$。
2. 如果$y_k$ 属于omega，那么我们就找到了一个元素
3. 如果不属于，纯在$a_j^T y_k > c_j$，就可以吧$E_k$切一半，然后找到一个包含$1/2E_k$的最小ellipsiod，即为$E_{k+1}$

接下来是最重要的内点法, 之后再看吧
 